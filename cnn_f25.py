# -*- coding: utf-8 -*-
"""colab_11/11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1caDM_7YsRns0_OVVqzZkvivIo8D4_tz9
"""

import torch

if torch.cuda.is_available():
  device = torch.device('cuda:0')
  print("Running on GPU")
  print(torch.cuda.get_device_name(0))
else:
  device = torch.device('cpu')
  print("Running on CPU")

class CustomDataset(torch.utils.data.Dataset):
  def __init__(self, images, labels):
    super(CustomDataset, self).__init__()
    self.x = images
    self.y = labels

  def __len__(self):
    return len(self.x)

  def __getitem__(self, i):
    return (self.x[i], self.y[i])


images = [1, 2, 3, 7, 8, 9, 10, 12, 15]
labels = [4, 5, 6, 15, 25, 37, 80, 78, 1]

trainData = CustomDataset(images, labels)

BATCH_SIZE = 1
trainLoader = torch.utils.data.DataLoader(trainData, batch_size = BATCH_SIZE, shuffle = True)

next(iter(trainLoader))

import torchvision

train_dataset = torchvision.datasets.CIFAR10(root = './cifar10', transform=torchvision.transforms.ToTensor(), download = True)
test_dataset = torchvision.datasets.CIFAR10(root = './cifar10', train = False, transform=torchvision.transforms.ToTensor(), download = True)

import matplotlib.pyplot as plt

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 128)

train_iter = iter(train_loader)

batch_images, batch_labels = next(train_iter)

image = batch_images[40]
label = batch_labels[40]

print(image.shape, label)
plt.imshow(image.permute(1, 2, 0))
plt.show

import torch.nn as nn

class CNN(nn.Module):
    def __init__(self, channels, kernels, paddings, strides, poolings, linears):
        super(CNN, self).__init__()


        self.layer1 = nn.Linear(567, 234)
        self.activation1 = nn.ReLU()
        self.layer2 = nn.Linear(234, 128)
        self.activation2 = nn.ReLU()
        self.layer3 = nn.Linear(128, 10)

        channels = [3] + channels
        size_after_each = 32

        self.conv_layers = []

        for i in range(len(channels) - 1):
          size_after_each = int(((size_after_each - kernels[i] + 2*paddings[i])/strides[i] + 1)/poolings[i])
          self.conv_layers.append(
              nn.Sequential(
                  nn.Conv2d(channels[i], channels[i+1], kernel_size = kernels[i], padding = paddings[i], stride = strides[i]),
                  nn.MaxPool2d(poolings[i], poolings[i]),
                  nn.BatchNorm2d(channels[i+1]),
                  nn.ReLU(),
                  nn.Dropout(0.05)
              )
          )

        self.skip_connection = nn.Sequential(
            nn.Conv2d(3, channels[-1], kernel_size = 3, padding = 1, stride = 4),
            nn.MaxPool2d(5, 5),
            nn.BatchNorm2d(channels[i+1]),
            nn.Dropout(0.05)
        )

        self.conv_layers = nn.Sequential(*self.conv_layers)

        self.flattener = nn.Flatten()
        self.fc_layers = []

        linears = [channels[-1] * size_after_each * size_after_each] + linears

        for i in range(len(linears) - 1):
          self.fc_layers.append(
            nn.Sequential(
                 nn.Linear(linears[i], linears[i+1]),
                 nn.ReLU(),
                 nn.Dropout(0.05)
             )
         )

        self.fc_layers = nn.Sequential(*self.fc_layers)

        self.final_layer = nn.Linear(linears[-1], 10)
        self.softmax = nn.Softmax()

    def forward(self, x):
        x = self.conv_layers(x) # convolutions
        x = self.flattener(x) # flatten
        x = self.fc_layers(x) # line
        x = self.final_layer(x)
        return self.softmax(x)

model = CNN([4, 8, 16, 32, 64, 128, 256, 128, 64, 32],
            [3]*11,
            [1]*11,
            [1, 2, 2]*3 + [1, 2],
            [1]*11,
            [256, 128, 64, 64, 32, 16]).to(device)

output = model.forward(batch_images.to(device))
print(model)
print(sum(p.numel() for p in model.parameters()), "parameters")

class myModel(nn.Module):
  def __init__(self):
    super(myModel, self).__init__self()
    self.long_term_mem = []

  def forward(self, x):
    return x

def evaluationLoop(modelToTest, testingData, lossFunc, BATCH_SIZE, preprocessing):
  testDataLoader = torch.utils.data.DataLoader(testingData, batch_size=BATCH_SIZE, shuffle = True)
  modelToTest.eval() # will not store gradients

  allPreds = torch.Tensor([]).to(device)
  allAnswers = torch.Tensor([]).to(device)
  runningLoss = 0
  countOfCorrectlyClassified = 0

  for batch_inputs, actualLabels in iter(testDataLoader):
    batch_inputs = batch_inputs.to(device)
    actualLabels = actualLabels.to(device)

    preprocessed_batch_inputs = preprocessing(batch_inputs)
    predictions = modelToTest.forward(preprocessed_batch_inputs)
    predicted_classes = predictions.argmax(dim=1) # (batch_size, 1)
    currentLoss = lossFunc(predictions, actualLabels)

    allPreds = torch.cat([allPreds, predicted_classes])
    allAnswers = torch.cat([allAnswers, actualLabels])
    runningLoss += currentLoss.item()
    countOfCorrectlyClassified += (predicted_classes == actualLabels).sum().item()

  return (allPreds,
          allAnswers,
          runningLoss/len(testDataLoader),
          countOfCorrectlyClassified)

def trainingLoop(modelToTrain, trainingData, lossFunc, myOptimizer, EPOCHS, BATCH_SIZE, preprocessing, testingData = None):

  trainDataLoader = torch.utils.data.DataLoader(trainingData, batch_size = BATCH_SIZE, shuffle = True) # splits our training dataset into our batches

  modelToTrain.train() # model to be trainable
  losses = [] # store losses
  test_accuracies = [] # store the validation accuracy

  total_batches_per_epoch = round(len(trainingData) / BATCH_SIZE) # calculating the number of batches you have in the training data loader
  for current_epoch_num in range(EPOCHS): # start training by looping over epochs
    loss_per_epoch = 0 # storing the loss per epoch
    for num, (batch_inputs, actualLabels) in enumerate(iter(trainDataLoader)): # iterating through all of the batches in our dataLoader
      batch_inputs = batch_inputs.to(device) # inputs and our labels to CUDA
      actualLabels = actualLabels.to(device)
      preprocessed_batch_inputs = preprocessing(batch_inputs) # preprocessing
      predictions = modelToTrain.forward(preprocessed_batch_inputs) # forward pass
      currentLoss = lossFunc(predictions, actualLabels) # calculate our loss (the loss function telling the model how wrong its predictions are)
      currentLoss.backward() # calculate the gradient (how to update the weights to get better performance), backpropagation
      myOptimizer.step() # gradient descent
      myOptimizer.zero_grad() # zero out the gradient so it doesn't accumulate

      if (num % 100 == 99):
        print(f"       Batch {num+1}/{total_batches_per_epoch}")

      loss_per_epoch += currentLoss.item()

    losses.append(loss_per_epoch/len(trainDataLoader))

    if testingData is not None: # validation
      val_stats = evaluationLoop(modelToTrain, testingData, lossFunc, BATCH_SIZE, preprocessing) # running the evaluation loop
      val_accuracy = (val_stats[3]/len(val_stats[1])) # calculate its accuracy and report it
      print(f"Validation accuracy: {100*val_accuracy:.2f}%")
      test_accuracies.append(val_accuracy)

  print(f"Done with training over {EPOCHS} epochs; Average Loss: {losses[-1]}")

  return losses

initialLosses = evaluationLoop(
    model,
    test_dataset,
    nn.CrossEntropyLoss(),
    128,
    lambda x: x
)

losses = trainingLoop(model,
                      train_dataset,
                      nn.CrossEntropyLoss(),
                      torch.optim.Adam(model.parameters(), lr = 0.00001),
                      100,
                      128,
                      lambda x: x,
                      test_dataset)

finalLosses = evaluationLoop(
    model,
    test_dataset,
    nn.CrossEntropyLoss(),
    128,
    lambda x: x
)

from sklearn import metrics
from matplotlib import pyplot as plt

plt.imshow(metrics.confusion_matrix(initialLosses[0].cpu().numpy(), initialLosses[1].cpu().numpy()))

plt.imshow(metrics.confusion_matrix(finalLosses[0].cpu().numpy(), finalLosses[1].cpu().numpy()))